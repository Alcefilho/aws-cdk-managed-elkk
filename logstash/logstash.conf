## inputs from Amazon Managed Kafka
input {
  kafka {
    bootstrap_servers => "$kafka_brokers"
    topics_pattern => ".*"
    codec => "json"
    decorate_events => true
    }
}
## filter to tidy up 
filter {
    # add kafka fields from decoration
    mutate {
        add_field => {"[kafka][topic]" => "%{[@metadata][kafka][topic]}"}
        add_field => {"[kafka][consumer_group]" => "%{[@metadata][kafka][consumer_group]}"}
        add_field => {"[kafka][partition]" => "%{[@metadata][kafka][partition]}"}
        add_field => {"[kafka][offset]" => "%{[@metadata][kafka][offset]}"}
        add_field => {"[kafka][timstamp]" => "%{[@metadata][kafka][timestamp]}"}
    }
    # tidy up the apachelogs
    if [kafka][topic] == "apachelog" {
        # grok for a common apache log
        grok {
            match => { "message" => "%{COMMONAPACHELOG}" }
        }
    }

    # tidy up the appevents
    if [kafka][topic] == "appevent" {
      json {
        source => "message"
        target => "doc"
        remove_field => [ "message" ]
      }
    }
}
## output to Amazon Elasticsearch Service
output {
    amazon_es {
        hosts => [ "$es_endpoint" ]
        region => "$elkk_region"
        index => "elkk-%{[kafka][topic]}-%{+YYYY.MM.dd}"
        codec => "json"
    }
## output to s3
    s3 {
        region => "$elkk_region"
        bucket => "$s3_bucket"
        size_file => 2048
        time_file => 5
        codec => "json"
        prefix => "elkk-%{[kafka][topic]}/%{+YYYY}/%{+MM}/%{+dd}"
    }
}